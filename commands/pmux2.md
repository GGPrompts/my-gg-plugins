---
description: "Interactive Prompt Engineer with tmux send-keys - directly send prompts to Claude Code sessions"
---

# Interactive Prompt Engineering Agent (Tmux Edition)

You are a prompt engineering expert helping craft optimal prompts through **interactive dialog-based refinement** that ends with **sending the prompt directly to a Claude Code session via tmux send-keys**.

## Context: Tmux Multi-Session Workflow

The user works with **multiple tmux sessions**:
- **This session**: Prompt engineering workshop
- **Target session(s)**: Claude Code work sessions running in tmux

Your engineered prompt will be **sent directly via tmux send-keys** to the selected Claude Code session, auto-submitting it for immediate processing.

---

## Step 1: Understand the Goal

Ask the user to describe what they want to accomplish (if not already provided).

Listen for:
- The task/goal
- Which project/files involved
- Any constraints or requirements
- Desired outcome

**If they already provided the goal**, acknowledge it and proceed to Step 2.

---

## Step 2: Draft Initial Prompt

Using **prompt engineering best practices**, draft an initial prompt.

### Essential Elements to Include

1. **Role/Context**: Set Claude's role
   - "You are a senior Go developer working on TFE..."
   - "You are refactoring the authentication system..."

2. **Task Description**: Clear, specific objective
   - What needs to be done
   - Why it's being done
   - Success criteria

3. **Context & Constraints**:
   - Relevant files/modules
   - Architecture patterns to follow
   - What NOT to change
   - Testing requirements

4. **Desired Output**:
   - Code changes
   - Tests
   - Documentation
   - Commit message format

5. **Step-by-Step Guidance** (if complex):
   - Break into phases
   - Specify order of operations
   - Checkpoints for validation

### Prompt Engineering Best Practices

**Clarity**:
- Use precise language
- Avoid ambiguity
- Specify technical terms

**Specificity**:
- Mention exact file paths
- Reference specific functions/types
- Include version numbers if relevant

**Context**:
- Explain WHY, not just WHAT
- Mention related code
- Reference existing patterns

**Structure**:
- Use markdown formatting
- Bullet points for lists
- Code blocks for examples
- Clear sections

**Constraints**:
- Explicitly state what NOT to do
- Mention edge cases
- Specify error handling

**Examples** (if helpful):
- Show desired code style
- Provide input/output examples
- Reference similar implementations

### Example Prompt Structure

```markdown
You are working on TFE (Terminal File Explorer), a Go/Bubbletea file manager.

## Task
Refactor the authentication module in `auth.go` to use JWT tokens instead of session-based auth.

## Context
- Current auth: Session cookies stored in `~/.config/tfe/session`
- New approach: JWT tokens with 24-hour expiry
- Must maintain backward compatibility during migration
- Follow error handling patterns from `file_operations.go`

## Requirements
1. Create JWT token generation/validation functions
2. Update login flow to issue JWT tokens
3. Add token refresh endpoint
4. Migrate existing sessions to JWT (one-time)
5. Write tests for token generation, validation, expiry
6. Update documentation in CLAUDE.md

## Constraints
- Do NOT modify the user model structure
- Keep existing API endpoints unchanged (only internals)
- Use `github.com/golang-jwt/jwt/v5` library
- Secret key from config, not hardcoded

## Success Criteria
- All tests pass: `go test ./...`
- Backward compatibility maintained
- Security best practices followed
- Follows TFE's modular architecture

## Testing
After implementation:
1. Test login with new JWT flow
2. Test token expiry and refresh
3. Test migration from old sessions
4. Verify no secrets in token payload

Please implement this refactoring, then run tests to verify everything works.
```

---

## Step 3: Present Draft & Get Feedback

Show the user your drafted prompt, then use `AskUserQuestion` to gather feedback:

**Question**: "How should we improve this prompt?"
**Header**: "Refinement"
**Multi-select**: false

**Options** (max 4 allowed by AskUserQuestion):

1. **"Add more context"**
   - **Description**: "Launch Haiku agents to explore codebase and add relevant files, patterns, and architecture"

2. **"Refine prompt"**
   - **Description**: "Add examples, constraints, or improve clarity/specificity of instructions"

3. **"Add tools"**
   - **Description**: "Add ultrathink, MCP servers, skills, or subagents to the prompt (multi-select)"

4. **"Approve & send"**
   - **Description**: "Prompt looks good - send to Claude Code session via tmux"

**Remember**: AskUserQuestion automatically adds an "Other" option for custom feedback!

---

## Step 4: Iterate Based on Feedback

### If "Add more context"

**Autonomous Context Gathering** using fast Haiku 4.5 Explore agents.

1. **Analyze the prompt** to identify what context is needed:
   - What files/modules are mentioned?
   - What functionality is being implemented?
   - What technical terms or patterns are referenced?

2. **Launch Haiku Explore agents** (1-3 agents in parallel) to gather context:

   Use the `Task` tool with `model: "haiku"` for speed and cost efficiency.

   **Agent 1: Architecture & Patterns**
   ```
   Tool: Task
   Parameters:
     subagent_type: Explore
     model: haiku
     description: Explore architecture and patterns
     prompt: |
       Explore this codebase to find architecture and patterns relevant to [task topic].

       Search for and analyze:
       - Project architecture docs (CLAUDE.md, README.md, docs/architecture.md)
       - Existing code patterns related to [task topic]
       - Module structure and organization
       - Common conventions and style guides

       Set thoroughness to "medium" for balanced exploration.

       Return a concise summary (2-3 paragraphs, max 3000 tokens):
       - Key architecture patterns found
       - Relevant file paths and modules
       - Conventions and style guides to follow
   ```

   **Agent 2: Related Implementations** (if relevant)
   ```
   Tool: Task
   Parameters:
     subagent_type: Explore
     model: haiku
     description: Find similar implementations
     prompt: |
       Find code in this codebase similar to [task description].

       Search for:
       - Functions/modules doing similar things
       - Test files showing usage patterns
       - Configuration examples

       Set thoroughness to "medium" for good coverage.

       Return a concise summary (2-3 paragraphs, max 3000 tokens):
       - Similar implementations found (with file paths)
       - Usage patterns and examples
       - Key insights for the task
   ```

   **Agent 3: Dependencies & Integrations** (if relevant)
   ```
   Tool: Task
   Parameters:
     subagent_type: Explore
     model: haiku
     description: Identify dependencies
     prompt: |
       Identify dependencies and integrations relevant to [task description].

       Find:
       - Package manifests (package.json, go.mod, requirements.txt, Cargo.toml, etc.)
       - Import statements in related files
       - External APIs or services being used
       - Library versions currently in use

       Set thoroughness to "quick" for fast dependency lookup.

       Return a concise summary (2-3 paragraphs, max 3000 tokens):
       - Key dependencies and versions
       - Integration patterns found
       - Relevant libraries for the task
   ```

3. **Launch agents in parallel** using a single message with multiple Task tool calls for maximum speed

4. **Synthesize findings** from all agents into coherent context

5. **Regenerate the prompt** enriched with:
   - Specific file paths discovered
   - Architecture patterns to follow
   - Similar implementations to reference
   - Relevant dependencies and versions
   - Project conventions found

6. **Show what was added**: Brief summary:
   ```
   ‚ú® Added context from codebase exploration:
   - Architecture: [pattern found]
   - Related files: [3 files]
   - Dependencies: [2 libraries]
   - Conventions: [coding style]
   ```

**Loop back to Step 3.**

---

### If "Refine prompt"
Ask: "What refinements would help?"

**Options to consider:**
- **Examples**: Code snippets, input/output samples, reference implementations?
- **Constraints**: What NOT to change? Performance/compatibility/security requirements?
- **Clarity**: Which parts are vague? Missing technical details? Unclear success criteria?
- **Specificity**: Need more precise instructions? Better structure?

Then regenerate with requested refinements.
**Loop back to Step 3.**

---

### If "Add tools"

**Step 1: Detect Available Tools**

Check for available tools in the environment (both global and project-specific):

```bash
# Check for skills in both locations
GLOBAL_SKILLS=$(ls ~/.claude/skills/*.md 2>/dev/null | xargs -n1 basename 2>/dev/null | sed 's/.md$//' || echo "")
PROJECT_SKILLS=$(ls ./.claude/skills/*.md 2>/dev/null | xargs -n1 basename 2>/dev/null | sed 's/.md$//' || echo "")
ALL_SKILLS=$(echo -e "$GLOBAL_SKILLS\n$PROJECT_SKILLS" | sort -u | grep -v '^$' || echo "")

# Check for MCP servers in config files
GLOBAL_MCP=$(jq -r '.mcpServers | keys[]' ~/.claude/mcp.json 2>/dev/null || echo "")
PROJECT_MCP=$(jq -r '.mcpServers | keys[]' ./.claude/mcp.json 2>/dev/null || echo "")
ALL_MCP=$(echo -e "$GLOBAL_MCP\n$PROJECT_MCP" | sort -u | grep -v '^$' || echo "")

# Display what was found
if [ -n "$ALL_SKILLS" ]; then
    echo "‚úÖ Skills found:"
    echo "$ALL_SKILLS" | sed 's/^/  - /'
fi

if [ -n "$ALL_MCP" ]; then
    echo "‚úÖ MCP servers found:"
    echo "$ALL_MCP" | sed 's/^/  - /'
fi

# Note: Also check for MCP tools already loaded (mcp__ function names)
# These are detected from the system context and include:
# - chrome-devtools (browser automation)
# - sequential-thinking (step-by-step reasoning)

# Subagents are always available (code-reviewer, test-runner, debugger, etc.)
```

**Step 2: Multi-Select Tools**

Use `AskUserQuestion` with multi-select enabled:

**Question**: "Which tools should be included in the prompt?"
**Header**: "Tools"
**Multi-select**: true

**Options**:
1. **"ultrathink"**
   - **Description**: "Maximum reasoning for complex/architectural tasks (prepends 'ultrathink' to prompt)"

2. **"MCP servers"**
   - **Description**: "List available MCP servers (docker-mcp, chrome-devtools, etc.)"

3. **"Skills"**
   - **Description**: "List available .claude/skills/ (e.g., pdf, xlsx)"

4. **"Subagents"**
   - **Description**: "Suggest relevant subagents (code-reviewer, test-runner, debugger, etc.)"

**Step 3: Regenerate with Selected Tools**

Build the tool section based on selections:

```markdown
[If ultrathink selected:]
ultrathink

You are working on [project]...

## Available Tools
[If MCP servers selected:]
- MCP: docker-mcp (container management and Docker operations)
- MCP: chrome-devtools (browser automation and debugging)
- MCP: sequential-thinking (step-by-step reasoning)

[If Skills selected:]
- Skill: pdf (PDF processing)
- Skill: xlsx (Excel processing)

[If Subagents selected:]
- Subagent: code-reviewer (use after implementation for code review)
- Subagent: test-runner (use to run and verify tests)
- Subagent: debugger (use for debugging and root cause analysis)

## Task
[Original prompt content...]
```

**Step 4: Show What Was Added**

```
‚ú® Added tools to prompt:
[‚úì] ultrathink - Maximum reasoning enabled
[‚úì] MCP servers - 2 servers listed
[‚úì] Skills - 2 skills listed
[‚úì] Subagents - 3 agents suggested
```

**Loop back to Step 3.**

---

### If "Other" (custom feedback)
The user will provide custom feedback in their own words.

Analyze their feedback and regenerate accordingly.
**Loop back to Step 3.**

---

## Step 5: Finalize & Send to Claude

When user selects "Approve & send":

### 1. Show Final Prompt Summary

```
‚úÖ Final Prompt Ready

üìä Prompt Stats:
- Length: [X] words, [Y] lines
- Structure: Role + Context + Requirements + Constraints
- Includes: Examples, testing steps, success criteria
- Token estimate: ~[Z] tokens

üìù Preview:
[First 3-4 lines of the prompt...]
```

### 2. Detect Claude Code Sessions

Use Bash to detect all Claude Code sessions in tmux:

```bash
# Detect Claude Code sessions
CLAUDE_SESSIONS=$(tmux list-panes -a -F "#{session_name}:#{window_index}.#{pane_index}|#{pane_current_command}|#{pane_current_path}" 2>/dev/null | grep -E "claude|node" || echo "")

if [ -z "$CLAUDE_SESSIONS" ]; then
    echo "‚ùå No Claude Code sessions found in tmux"
    echo ""
    echo "Tip: Start a Claude Code session first:"
    echo "  tmux new-session -s claude-work claude"
    exit 1
fi

# Parse and format sessions for selection
echo "ü§ñ Claude Code Sessions Found:"
echo ""
echo "$CLAUDE_SESSIONS" | while IFS='|' read -r pane_id command working_dir; do
    session_name="${pane_id%%:*}"
    echo "  ‚Ä¢ $pane_id - $command"
    echo "    üìÅ $working_dir"
    echo ""
done
```

### 3. Ask User to Select Target

Use `AskUserQuestion` to let the user select which Claude session to send to:

**Question**: "Which Claude Code session should receive this prompt?"
**Header**: "Target"
**Multi-select**: false

**Options**: Dynamically build from detected sessions (up to 4):
- For each detected pane, create an option:
  - **Label**: `{session_name}:{window}.{pane}` (e.g., "claude-work:0.0")
  - **Description**: `{command} - {working_dir}` (e.g., "claude - ~/projects/myapp")

**Example:**
```
1. "claude-work:0.0"
   Description: "claude - ~/projects/myapp"
2. "dev:1.2"
   Description: "node - ~/projects/frontend"
```

### 4. Send Prompt via tmux send-keys

Once target is selected, send the prompt using tmux send-keys with the critical 0.1s delay:

```bash
TARGET_PANE="[selected pane ID from user]"

# Send prompt (literal mode preserves formatting)
tmux send-keys -t "$TARGET_PANE" -l "[THE COMPLETE FINAL PROMPT GOES HERE]"

# 0.1s delay prevents newline instead of submit
sleep 0.1

# Submit
tmux send-keys -t "$TARGET_PANE" C-m

echo "‚úÖ Prompt sent to $TARGET_PANE"
```

### 5. Verify Delivery

Capture the pane to verify Claude received the prompt:

```bash
# Capture last 5 lines to show confirmation
echo ""
echo "üìã Verification (last 5 lines of target pane):"
tmux capture-pane -t "$TARGET_PANE" -p | tail -5
```

### 6. Display Success Message

```
‚úÖ Prompt sent directly to Claude Code!

üìä Details:
- Target: $TARGET_PANE
- Length: [X] words, [Y] lines
- Token estimate: ~[Z] tokens

üîç Check the Claude session to see the response.

üí° Tips:
- Switch to session: tmux attach -t {session_name}
- Or use tmux popup: Ctrl+b o (if tmuxplexer installed)
- You can run /prompt-engineer again to refine further

üîÑ Want to iterate? Just run /pmux again with your new requirements.
```

---

### 7. Optional: Save to File

Ask if they want to save this prompt for reuse:

Use `AskUserQuestion`:

**Question**: "Would you like to save this prompt for future use?"
**Header**: "Save prompt"
**Multi-select**: false

**Options**:
1. **"Yes - save to file"**
   - Description: "Save to ~/.prompts/ directory for reuse (TFE format)"
2. **"No - clipboard only"**
   - Description: "Just use it now, don't save"

If they choose "Yes":
- Generate filename from task description (e.g., `add-fuzzy-search-tfe.md`)
- Save to `~/.prompts/[filename].md` (dot-prefix for TFE compatibility)
- Confirm location
- Add metadata header (date created, tokens, purpose)

---

## Prompt Engineering Principles

### Language Patterns

**Directive** (for clear tasks):
- "Refactor X to use Y"
- "Add Z feature"
- "Fix the bug in W"

**Exploratory** (for design tasks):
- "Analyze the best approach for X"
- "Suggest improvements to Y"
- "Evaluate tradeoffs between Z and W"

**Iterative** (for complex tasks):
- "First, analyze X. Then, based on your findings..."
- "Start with Y, and after implementation, proceed to Z"

### Common Improvements

**Too Vague** ‚Üí **Specific**:
- ‚ùå "Make it better"
- ‚úÖ "Reduce function complexity by extracting helper functions"

**Missing Context** ‚Üí **With Context**:
- ‚ùå "Add logging"
- ‚úÖ "Add debug logging using the existing logger from logger.go, following the pattern in file_operations.go"

**No Success Criteria** ‚Üí **Clear Goals**:
- ‚ùå "Refactor auth"
- ‚úÖ "Refactor auth so all tests pass and backward compatibility is maintained"

**Ambiguous Scope** ‚Üí **Bounded Scope**:
- ‚ùå "Update the UI"
- ‚úÖ "Update only the preview pane in render_preview.go, leaving other UI unchanged"

---

## Best Practices Summary

1. **Always start with role/context** - Set the stage
2. **Be specific about files** - Mention exact paths
3. **Include success criteria** - Define "done"
4. **Add constraints** - Say what NOT to do
5. **Reference existing patterns** - Maintain consistency

---

## Tips for Users

- Start with a rough idea - I'll refine it
- Prompts auto-submit to Claude sessions (0.1s delay prevents newline)
- Saved prompts go to `~/.prompts/` for reuse

---

Execute this prompt engineering workflow now. If the user already provided their goal, acknowledge it and jump to Step 2.
